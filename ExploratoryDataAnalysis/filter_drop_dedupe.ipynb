{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter, Drop Nulls, Dedupe\n",
    "Use `data_08_v2.csv` and `data_18_v2.csv`. You should've created these data files in the previous section: *Renaming Columns*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# import pandas and load datasets\n",
    "\n",
    "df_08 = pd.read_csv('data_08_v2.csv')\n",
    "df_18 = pd.read_csv('data_18_v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2404, 14)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view dimensions of dataset\n",
    "df_08.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1611, 14)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view dimensions of dataset\n",
    "df_18.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter by Certification Region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use .query() to filter datasets for rows following California standards\n",
    "# You can user the cert_region column to filter\n",
    "df_08 = df_08.query('cert_region == \"CA\"')\n",
    "df_18 = df_18.query('cert_region == \"CA\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CA'], dtype=object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confirm only certification region is California\n",
    "df_08['cert_region'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CA'], dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confirm only certification region is California\n",
    "df_18['cert_region'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# drop certification region columns form both df_08 and df_18 datasets\n",
    "# you no longer this column since all data should now \n",
    "# be filtered by California\n",
    "# Assign the result back to the DataFrame without using inplace\n",
    "df_08 = df_08.drop(columns='cert_region')\n",
    "df_18 = df_18.drop(columns='cert_region')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1084, 13)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_08.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(798, 13)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_18.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop Rows with Missing Values\n",
    "As a reminder, you can use the `.isnull()` method to view how many null values are in each column.  \n",
    "To count every null from every column, sum the values returned from `.isnull()` by using `.sum()` to return a total count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model                    0\n",
       "displ                    0\n",
       "cyl                     75\n",
       "trans                   75\n",
       "drive                   37\n",
       "fuel                     0\n",
       "veh_class                0\n",
       "air_pollution_score      0\n",
       "city_mpg                75\n",
       "hwy_mpg                 75\n",
       "cmb_mpg                 75\n",
       "greenhouse_gas_score    75\n",
       "smartway                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view missing value count for each feature in 2008\n",
    "df_08.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model                   0\n",
       "displ                   1\n",
       "cyl                     1\n",
       "trans                   0\n",
       "drive                   0\n",
       "fuel                    0\n",
       "veh_class               0\n",
       "air_pollution_score     0\n",
       "city_mpg                0\n",
       "hwy_mpg                 0\n",
       "cmb_mpg                 0\n",
       "greenhouse_gas_score    0\n",
       "smartway                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view missing value count for each feature in 2018\n",
    "df_18.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# drop rows with any null values in both datasets\n",
    "\n",
    "df_08.dropna(inplace=True)\n",
    "\n",
    "df_18.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checks if any of columns in 2008 have null values - should print False\n",
    "df_08.isnull().sum().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checks if any of columns in 2018 have null values - should print False\n",
    "df_18.isnull().sum().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dedupe Data\n",
    "Check if there are duplicate values in your DataFrames by using the `.duplicated()` function. Read more on the functionality [here](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.duplicated.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print number of duplicates in 2008 and 2018 datasets\n",
    "# remember to use .sum() on the retured values from .duplicated() to count all total duplicates.\n",
    "df_08.duplicated().sum()\n",
    "df_18.duplicated().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# drop duplicates in both datasets\n",
    "df_08.drop_duplicates(inplace=True)\n",
    "df_18.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# print number of duplicates again to confirm dedupe - should both be 0\n",
    "\n",
    "print(df_08.duplicated().sum())\n",
    "print(df_18.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save progress for the next section\n",
    "df_08.to_csv('data_08_v3.csv', index=False)\n",
    "df_18.to_csv('data_18_v3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
